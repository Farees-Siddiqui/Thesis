{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import re\n",
    "\n",
    "from transformers import BertTokenizerFast, BertModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "from pprint import pprint\n",
    "import io\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper import stream\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "# Length of dataset: 2,326,839\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stream = stream()\n",
    "next(data_stream).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2057,  6235,  1037,  2047,  9896,  1010,  1996,  1002,  1006,\n",
       "          1047,  1010,  1032,  3449,  2140,  1007,  1002,  1011, 21877, 11362,\n",
       "          2208,  2007,  6087,  1010,  1998,  2224,  2009,  6855,  1037, 23191,\n",
       "          1997,  1996,  2155,  1997,  1002,  1006,  1047,  1010,  1032,  3449,\n",
       "          2140,  1007,  1002,  1011, 20288, 19287,  1998,  9896,  2594,  7300,\n",
       "          2000,  1037,  2155,  1997,  3471,  7175,  3392, 22511,  2015,  1997,\n",
       "         19287,  1012,  2569, 12107,  1997, 20288, 19287,  3711,  1999, 11841,\n",
       "          3012,  3399,  1998,  2031,  2363,  3445,  3086,  1999,  3522,  2086,\n",
       "          1012,  1999,  3327,  1010,  2256,  6910, 28962,  2236,  4697,  1998,\n",
       "         12919,  1996,  3025,  3463,  1997,  3389,  1998,  2358,  2890,  2378,\n",
       "          2226,  1998,  2507,  1037,  2047,  6947,  1997,  1996, 10722,  4674,\n",
       "          1011, 10594,  1011,  3766, 23191,  1997, 19679, 28775,  3723,  1012,\n",
       "          2057,  2036,  2556,  1037,  2047, 22511,  2008,  8292, 28228, 14213,\n",
       "         12403,  2869,  3012,  2241,  2006,  1996,  1002,  1006,  1047,  1010,\n",
       "          1032,  3449,  2140,  1007,  1002,  1011, 21877, 11362,  2208,  2007,\n",
       "          6087,  1012,  2256,  2147,  2036, 14451,  2015,  7264,  2090, 21877,\n",
       "         11362,  2208, 13792,  1998,  3025, 20288, 10629, 13792,  2011, 11721,\n",
       "         18912,  1010, 11721, 18912,  1998,  2225, 18689,  2078,  1998, 28895,\n",
       "          2239,  1012,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_data(data):\n",
    "    tokenized_data = tokenizer(data, padding=True, truncation=True, return_tensors='pt')\n",
    "    tokenized_data.to(device)\n",
    "    return tokenized_data\n",
    "\n",
    "tokenize_data(next(data_stream)['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_to_sql_string(vector):\n",
    "    vector = vector.cpu().numpy().tolist()\n",
    "    sql_string = ['\"' + str(i) + '\"' for i in vector]\n",
    "    \n",
    "    sql_string = '{' + ', '.join(sql_string) + '}'\n",
    "    \n",
    "    return sql_string\n",
    "\n",
    "def from_sql_to_list(string):\n",
    "    sql_string = re.findall(r'\\[.*?\\]', string)\n",
    "    lst = [eval(i) for i in sql_string]\n",
    "    return torch.tensor(np.array(lst), device=device, dtype=torch.float64)\n",
    "\n",
    "def connect_to_db():\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5432,\n",
    "        database=\"vector_database\",\n",
    "        user=\"postgres\",\n",
    "        password=\"admin\"\n",
    "    )\n",
    "    conn.autocommit = True\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n",
    "    return cur, conn\n",
    "\n",
    "cur, conn = connect_to_db()\n",
    "def save_batch(batch):    \n",
    "    for i in range(len(batch)):        \n",
    "        sql_string = vec_to_sql_string(batch[i]['Embedding'])\n",
    "        cur.execute(\"INSERT INTO article_embeddings VALUES (%s, %s, %s, %s)\", (i, batch[i]['Title'], batch[i]['Abstract'], sql_string))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 69, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed(article):\n",
    "    tokenized = tokenize_data(article)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokenized)\n",
    "        hidden_states = output.hidden_states\n",
    "        embedding = hidden_states[-2]\n",
    "    return embedding\n",
    "\n",
    "embed(next(data_stream)['abstract']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\faree\\Documents\\School\\ThirdYear\\Thesis\\GeneratingEmbeddings\\bert_embeddings_data_streaming.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/faree/Documents/School/ThirdYear/Thesis/GeneratingEmbeddings/bert_embeddings_data_streaming.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             batch \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/faree/Documents/School/ThirdYear/Thesis/GeneratingEmbeddings/bert_embeddings_data_streaming.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/faree/Documents/School/ThirdYear/Thesis/GeneratingEmbeddings/bert_embeddings_data_streaming.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m embed_and_append_to_csv()\n",
      "\u001b[1;32mc:\\Users\\faree\\Documents\\School\\ThirdYear\\Thesis\\GeneratingEmbeddings\\bert_embeddings_data_streaming.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/faree/Documents/School/ThirdYear/Thesis/GeneratingEmbeddings/bert_embeddings_data_streaming.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m embeddings_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/faree/Documents/School/ThirdYear/Thesis/GeneratingEmbeddings/bert_embeddings_data_streaming.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(embeddings_df))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/faree/Documents/School/ThirdYear/Thesis/GeneratingEmbeddings/bert_embeddings_data_streaming.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m embeddings_df\u001b[39m.\u001b[39;49mto_csv(output_csv, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/faree/Documents/School/ThirdYear/Thesis/GeneratingEmbeddings/bert_embeddings_data_streaming.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m batch \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/faree/Documents/School/ThirdYear/Thesis/GeneratingEmbeddings/bert_embeddings_data_streaming.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[1;32m--> 259\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save()\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[1;32m--> 264\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_body()\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39mif\u001b[39;00m start_i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m end_i:\n\u001b[0;32m    301\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_chunk(start_i, end_i)\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    310\u001b[0m data \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39miget_values(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res\u001b[39m.\u001b[39mitems))]\n\u001b[0;32m    312\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_index[slicer]\u001b[39m.\u001b[39m_format_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[1;32m--> 313\u001b[0m libwriters\u001b[39m.\u001b[39;49mwrite_csv_rows(\n\u001b[0;32m    314\u001b[0m     data,\n\u001b[0;32m    315\u001b[0m     ix,\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnlevels,\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcols,\n\u001b[0;32m    318\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwriter,\n\u001b[0;32m    319\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\writers.pyx:75\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:1588\u001b[0m, in \u001b[0;36m_array_str_implementation\u001b[1;34m(a, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[0;32m   1582\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m ():\n\u001b[0;32m   1583\u001b[0m     \u001b[39m# obtain a scalar and call str on it, avoiding problems for subclasses\u001b[39;00m\n\u001b[0;32m   1584\u001b[0m     \u001b[39m# for which indexing with () returns a 0d instead of a scalar by using\u001b[39;00m\n\u001b[0;32m   1585\u001b[0m     \u001b[39m# ndarray's getindex. Also guard against recursive 0d object arrays.\u001b[39;00m\n\u001b[0;32m   1586\u001b[0m     \u001b[39mreturn\u001b[39;00m _guarded_repr_or_str(np\u001b[39m.\u001b[39mndarray\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(a, ()))\n\u001b[1;32m-> 1588\u001b[0m \u001b[39mreturn\u001b[39;00m array2string(a, max_line_width, precision, suppress_small, \u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:736\u001b[0m, in \u001b[0;36marray2string\u001b[1;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m[]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 736\u001b[0m \u001b[39mreturn\u001b[39;00m _array2string(a, options, separator, prefix)\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:513\u001b[0m, in \u001b[0;36m_recursive_guard.<locals>.decorating_function.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m repr_running\u001b[39m.\u001b[39madd(key)\n\u001b[0;32m    512\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    514\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    515\u001b[0m     repr_running\u001b[39m.\u001b[39mdiscard(key)\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:539\u001b[0m, in \u001b[0;36m_array2string\u001b[1;34m(a, options, separator, prefix)\u001b[0m\n\u001b[0;32m    536\u001b[0m     summary_insert \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m \u001b[39m# find the right formatting function for the array\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m format_function \u001b[39m=\u001b[39m _get_format_function(data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[0;32m    541\u001b[0m \u001b[39m# skip over \"[\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m next_line_prefix \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:472\u001b[0m, in \u001b[0;36m_get_format_function\u001b[1;34m(data, **options)\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[39mreturn\u001b[39;00m formatdict[\u001b[39m'\u001b[39m\u001b[39mlongfloat\u001b[39m\u001b[39m'\u001b[39m]()\n\u001b[0;32m    471\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 472\u001b[0m         \u001b[39mreturn\u001b[39;00m formatdict[\u001b[39m'\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m'\u001b[39;49m]()\n\u001b[0;32m    473\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39missubclass\u001b[39m(dtypeobj, _nt\u001b[39m.\u001b[39mcomplexfloating):\n\u001b[0;32m    474\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(dtypeobj, _nt\u001b[39m.\u001b[39mclongfloat):\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:411\u001b[0m, in \u001b[0;36m_get_formatdict.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_formatdict\u001b[39m(data, \u001b[39m*\u001b[39m, precision, floatmode, suppress, sign, legacy,\n\u001b[0;32m    404\u001b[0m                     formatter, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    405\u001b[0m     \u001b[39m# note: extra arguments in kwargs are ignored\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \n\u001b[0;32m    407\u001b[0m     \u001b[39m# wrapped in lambdas to avoid taking a code path with the wrong type of data\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     formatdict \u001b[39m=\u001b[39m {\n\u001b[0;32m    409\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbool\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: BoolFormat(data),\n\u001b[0;32m    410\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: IntegerFormat(data),\n\u001b[1;32m--> 411\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: FloatingFormat(\n\u001b[0;32m    412\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[39m=\u001b[39;49mlegacy),\n\u001b[0;32m    413\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlongfloat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: FloatingFormat(\n\u001b[0;32m    414\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[39m=\u001b[39mlegacy),\n\u001b[0;32m    415\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcomplexfloat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: ComplexFloatingFormat(\n\u001b[0;32m    416\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[39m=\u001b[39mlegacy),\n\u001b[0;32m    417\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlongcomplexfloat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: ComplexFloatingFormat(\n\u001b[0;32m    418\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[39m=\u001b[39mlegacy),\n\u001b[0;32m    419\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: DatetimeFormat(data, legacy\u001b[39m=\u001b[39mlegacy),\n\u001b[0;32m    420\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtimedelta\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: TimedeltaFormat(data),\n\u001b[0;32m    421\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: _object_format,\n\u001b[0;32m    422\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mvoid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: str_format,\n\u001b[0;32m    423\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnumpystr\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: repr_format}\n\u001b[0;32m    425\u001b[0m     \u001b[39m# we need to wrap values in `formatter` in a lambda, so that the interface\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[39m# is the same as the above values.\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mindirect\u001b[39m(x):\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:932\u001b[0m, in \u001b[0;36mFloatingFormat.__init__\u001b[1;34m(self, data, precision, floatmode, suppress_small, sign, legacy)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexp_format \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlarge_exponent \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfillFormat(data)\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:965\u001b[0m, in \u001b[0;36mFloatingFormat.fillFormat\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    963\u001b[0m frac_strs, _, exp_strs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(s\u001b[39m.\u001b[39mpartition(\u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m strs))\n\u001b[0;32m    964\u001b[0m int_part, frac_part \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(s\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m frac_strs))\n\u001b[1;32m--> 965\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexp_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39;49m(\u001b[39mlen\u001b[39;49m(s) \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m exp_strs) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    967\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrim \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    968\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m frac_part)\n",
      "File \u001b[1;32mc:\\Users\\faree\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\arrayprint.py:965\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    963\u001b[0m frac_strs, _, exp_strs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(s\u001b[39m.\u001b[39mpartition(\u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m strs))\n\u001b[0;32m    964\u001b[0m int_part, frac_part \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(s\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m frac_strs))\n\u001b[1;32m--> 965\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexp_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m exp_strs) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    967\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrim \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    968\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m frac_part)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def embed_and_append_to_csv(output_csv='vector_db.csv'):\n",
    "    np.set_printoptions(threshold=sys.maxsize)\n",
    "    batch = []\n",
    "    batch_size = 32\n",
    "\n",
    "    for article in data_stream:\n",
    "        embedding = embed(article)\n",
    "        batch.append({'Title': article['title'], 'Abstract': article['abstract'], 'Embedding': embedding.detach().cpu().numpy()})\n",
    "        if len(batch) >= batch_size:        \n",
    "            embeddings_df = pd.DataFrame(batch)\n",
    "            print(len(embeddings_df))\n",
    "            embeddings_df.to_csv(output_csv, mode='a', header=False, index=False)\n",
    "            batch = []\n",
    "            break\n",
    "\n",
    "embed_and_append_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"drop table article_embeddings;\")\n",
    "cur.execute(\"create table article_embeddings(article_ID int primary key, article_title varchar, abstract varchar, embedding vector(768)[]);\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 788 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def embed_data(data_stream=data_stream):\n",
    "    batch = []\n",
    "    embeddings = []\n",
    "    batch_lim = 32\n",
    "    for article in data_stream:\n",
    "        emb = embed(article)\n",
    "        batch.append({'Title': article['title'], 'Abstract': article['abstract'], 'Embedding':torch.Tensor(emb.cpu().numpy())})\n",
    "        if len(batch) >= batch_lim:\n",
    "            # save_batch(batch)\n",
    "            embeddings.append(batch)\n",
    "            batch = []\n",
    "    save_batch(batch)\n",
    "embed_data()\n",
    "\n",
    "# Estimated time(in days) = (((WallTime/batch_lim) * 2'326'839)/3600)/24\n",
    "\n",
    "# TODO: Add a progress bar\n",
    "# TODO: Add a way to resume from a checkpoint\n",
    "# TODO: Save the batck to a csv instead, then use bulk copy to insert into the database\n",
    "# TODO: embed the articles in batches, bert can take batches of\n",
    "# TODO: start wiht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(batch):\n",
    "    # Tokenize the articles in batches of 10\n",
    "    tokenized = tokenize_data(batch)  # Assuming tokenize_data accepts a list of articles\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(**tokenized)\n",
    "        hidden_states = output.hidden_states\n",
    "        embedding = hidden_states[-2]\n",
    "    return embedding\n",
    "\n",
    "batch = []\n",
    "batch_size = 10\n",
    "for i in range(batch_size):\n",
    "    batch.append(next(data_stream)['abstract'])\n",
    "\n",
    "embed(batch).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
